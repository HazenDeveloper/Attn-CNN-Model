{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HazenDeveloper/Attn-CNN-Model/blob/main/CNN_FE_SVM_RF-LungsCancer-CV-01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IUzMl-LWi0Pl",
        "outputId": "3b25b527-bc5a-4052-e281-03f303230744",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFbjIBEyceKU"
      },
      "outputs": [],
      "source": [
        "#!pip install imutils\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "from keras.layers import Input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import Input\n",
        "from keras.layers import BatchNormalization\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model\n",
        "from sklearn.utils import shuffle\n",
        "from cv2 import imread\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4fuzmF_0Yvr",
        "outputId": "d4249013-db1b-4ad8-e4a0-71e491b9fa99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<built-in method count of list object at 0x7f935f48f800>\n"
          ]
        }
      ],
      "source": [
        "from os import listdir, walk\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from imutils import paths\n",
        "\n",
        "path = list(paths.list_images('/content/drive/MyDrive/ML-Datasets/LungsCancer'))\n",
        "print(([i.split(os.path.sep)[-2] for i in path]))\n",
        "\n",
        "# print('testing', imagePaths[1].split(os.path.sep)[-2])\n",
        "\n",
        "# img = cv2.imread(imagePaths[2])\n",
        "# cv2_imshow(img)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NJxQMYNe0cC",
        "outputId": "9bd43e8a-33c9-42be-dcdc-384f892a99b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1097 1097\n",
            "(1097, 256, 256, 3)\n",
            "(1097, 3)\n"
          ]
        }
      ],
      "source": [
        "data = []\n",
        "labels = []\n",
        "width,height=256,256\n",
        "depth = 3\n",
        "input_shape = (height, width, depth)\n",
        "\n",
        "classes = 3\n",
        "\n",
        "imagePaths = list(paths.list_images('/content/drive/MyDrive/ML-Datasets/LungsCancer'))\n",
        "\n",
        "train_data_dir = '/content/drive/MyDrive/ML-Datasets/LungsCancer/Normal'\n",
        "test_data_dir = '/content/drive/MyDrive/ML-Datasets/LungsCancer/Bengin'\n",
        "valid_data_dir = '/content/drive/MyDrive/ML-Datasets/LungsCancer/Malignant'\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for imagePath in imagePaths:\n",
        "    label = imagePath.split(os.path.sep)[-2]\n",
        "    image = load_img(imagePath, target_size=(width, height))\n",
        "    image = img_to_array(image)\n",
        "    data.append(image)\n",
        "    labels.append(label)\n",
        "\n",
        "data = np.array(data, dtype=\"float32\")\n",
        "labels = np.array(labels)\n",
        "print(len(data), len(labels))\n",
        "\n",
        "from sklearn.preprocessing import  LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# le = LabelEncoder()\n",
        "# labels = le.fit_transform(labels)\n",
        "\n",
        "# ohe = OneHotEncoder()\n",
        "# labels = ohe.fit_transform(labels)\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "\n",
        "#labels = to_categorical(labels)\n",
        "\n",
        "data, labels = shuffle(data, labels)\n",
        "\n",
        "print(data.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7P7hNcblOobe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtJkMb8RgeP3",
        "outputId": "a69f3847-dbb6-4585-b233-89dd8c096b78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images: (877, 256, 256, 3)\n",
            "Test images: (220, 256, 256, 3)\n",
            "Train label: (877, 3)\n",
            "Test label: (220, 3)\n"
          ]
        }
      ],
      "source": [
        "test_ratio = 0.2\n",
        "# train is now 75% of the entire data set\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=test_ratio)\n",
        "\n",
        "print(\"Train images:\",x_train.shape)\n",
        "print(\"Test images:\",x_test.shape)\n",
        "print(\"Train label:\",y_train.shape)\n",
        "print(\"Test label:\",y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xx_train, x_valid, yy_train, y_valid = train_test_split(x_train, y_train,test_size=test_ratio)"
      ],
      "metadata": {
        "id": "miBqYK_eylzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train images:\",x_train.shape)\n",
        "print(\"Test images:\",x_valid.shape)\n",
        "print(\"Train label:\",y_train.shape)\n",
        "print(\"Test label:\",y_valid.shape)"
      ],
      "metadata": {
        "id": "SbJEYBdvy8P5",
        "outputId": "09b5eb54-a5b2-4e8b-b2e2-de4fef9ccb68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images: (768, 256, 256, 3)\n",
            "Test images: (192, 256, 256, 3)\n",
            "Train label: (768, 4)\n",
            "Test label: (192, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train.shape[0])"
      ],
      "metadata": {
        "id": "87BtFGvszq8F",
        "outputId": "396c456a-9caa-4310-8fff-b948bddc9cf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MiniVGGNet(width, heigth, depth, classes):\n",
        "\tmodel = Sequential()\n",
        "\tinput_shape = (heigth, width, depth)\n",
        "\tchanDim = -1\n",
        "\n",
        "\tif keras.backend.image_data_format() == \"channel_first\":\n",
        "\t\tinput_shape = (depth, heigth, width)\n",
        "\t\tchanDim = 1\n",
        "\n",
        "\tmodel.add(Conv2D(16,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\t# model.add(Conv2D(32,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\t# model.add(Conv2D(64,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(Conv2D(32,(3,3), padding=\"same\", activation=\"relu\"))\n",
        "\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\t# model.add(Conv2D(64,(3,3), padding=\"same\", activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\t# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\t# model.add(Dropout(0.25))\n",
        "\n",
        "\t# model.add(Conv2D(128,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\t# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\t# model.add(Dropout(0.25))\n",
        "\n",
        "\t# model.add(BatchNormalization())\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(512, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization())\n",
        "\t# model.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(classes, activation=\"softmax\"))\n",
        "\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "0YVgmPybsCro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install scikit-plot\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scikitplot as skplt\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "import tensorflow\n",
        "\n",
        "# cnn_model = tensorflow.keras.models.load_model('best_model.h5')\n",
        "# x_test = test_generator\n",
        "# x_train = train_generator\n",
        "# y_test = test_generator.classes\n",
        "def plot_results(h):\n",
        "  # plot the training loss and accuracy\n",
        "  N = EPOCHS\n",
        "  plt.style.use(\"ggplot\")\n",
        "  plt.figure()\n",
        "  plt.plot(np.arange(0, N), h.history[\"loss\"], label=\"train_loss\")\n",
        "  plt.plot(np.arange(0, N), h.history[\"val_loss\"], label=\"val_loss\")\n",
        "  plt.title(\"Training Loss vs. validation Loss\")\n",
        "  plt.xlabel(\"Epoch #\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend(loc=\"lower left\",)\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(np.arange(0, N), h.history[\"accuracy\"], label=\"train_acc\")\n",
        "  plt.plot(np.arange(0, N), h.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "  plt.title(\"Training Accuracy vs. Validation Accuracy\")\n",
        "  plt.xlabel(\"Epoch #\")\n",
        "  plt.ylabel(\"Loss/Accuracy\")\n",
        "  plt.legend(loc=\"lower left\",)\n",
        "  plt.show()\n",
        "\n",
        "def evaluate_kth_fold(x_train, x_test):\n",
        "  print(\"[INFO] evaluating network...\")\n",
        "  predIdxs = cnn_model.predict(x_test)#, batch_size=BS)\n",
        "  predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "  trainpredIdxs = cnn_model.predict(x_train)#, batch_size=BS)\n",
        "  trainpredIdxs = np.argmax(trainpredIdxs, axis=1)\n",
        "\n",
        "  trainCNNScore=accuracy_score(trainpredIdxs,y_train.argmax(axis=1))*100\n",
        "  CNNScore=accuracy_score(predIdxs,y_test.argmax(axis=1))*100\n",
        "\n",
        "  return trainCNNScore, CNNScore"
      ],
      "metadata": {
        "id": "8t8sidYQj_GD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MiniVGGNetv01(model):\n",
        "  chanDim = -1\n",
        "  width,height=256,256\n",
        "  depth = 3\n",
        "  input_shape = (height, width, depth)\n",
        "\n",
        "  if keras.backend.image_data_format() == \"channel_first\":\n",
        "    input_shape = (depth, heigth, width)\n",
        "    chanDim = 1\n",
        "\n",
        "\n",
        "  model.add(Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  # model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  # model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "  # model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "  # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  # model.add(Dropout(0.25))\n",
        "\n",
        "  # model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "  # model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "  # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  # model.add(Dropout(0.25))\n",
        "\n",
        "  # model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "  # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  # model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, activation=\"relu\"))\n",
        "  # model.add(BatchNormalization())\n",
        "  # model.add(Dropout(0.25))\n",
        "  model.add(Dense(classes, activation=\"softmax\"))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "OhMc3MUUrC6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path where you want to save the best model\n",
        "checkpoint_path = 'best_model.h5'\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Create the ModelCheckpoint callback\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    patience = 2,\n",
        "    monitor='val_accuracy',       # Metric to monitor (could also be 'val_accuracy', etc.)\n",
        "    save_best_only=True,      # Saves only the best model based on the monitored metric\n",
        "    # save_weights_only=False,  # Set to True to save only the model's weights, not the whole model\n",
        "    verbose=1                 # Verbosity level: 0 - silent, 1 - progress bar, 2 - one line per epoch.\n",
        ")\n",
        "# checkpoint_callback = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "early_stopping_callback = EarlyStopping(monitor='val_accuracy', patience=6, mode='auto')\n",
        "my_callbacks = [model_checkpoint, early_stopping_callback]"
      ],
      "metadata": {
        "id": "xAGgR5THejdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width,height=256,256\n",
        "depth = 3\n",
        "input_shape = (height, width, depth)\n",
        "\n",
        "classes = 3\n",
        "depth = 3\n",
        "INIT_LR = 1e-3\n",
        "EPOCHS = 100\n",
        "BS=32\n",
        "\n",
        "from keras.optimizers import Nadam, SGD\n",
        "from sklearn.cross_validation import StratifiedKFold\n",
        "model = Sequential()\n",
        "h = []\n",
        "Kfold = StratfiedKFold(n_splits=8)\n",
        "for train, test in Kfold.splits(data, labels):\n",
        "  cnn_model = None\n",
        "  # opt = Nadam(learning_rate=INIT_LR)\n",
        "  opt = SGD(learning_rate=INIT_LR)\n",
        "  # opt = Adam(learning_rate=INIT_LR)\n",
        "\n",
        "  cnn_model = MiniVGGNet(width, height, depth, classes)\n",
        "  cnn_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])#, run_eagerly=True)\n",
        "  # cnn_model.summary()\n",
        "  h = cnn_model.fit(train, test, epochs=EPOCHS, batch_size=BS, validation_split = 0.2, callbacks=my_callbacks)\n",
        "  print(\"Done !!\")\n",
        "\n",
        "  trainCNNScore, CNNScore = evaluate_kth_folder(x_train, x_test)\n",
        "\n",
        "  print(\"\\nTrainig Accuracy Score:-\",trainCNNScore)\n",
        "  print(\"\\nTesting Accuracy Score:-\",CNNScore)\n",
        "  print(\"\\nTraning Graph:- \\n \")\n",
        "\n",
        "  plot_results(h)\n",
        "\n",
        "  # cnn_model = MiniVGGNetv01(model)\n",
        "# opt = gradient_descent_legacy.SGD (learning_rate = INIT_LR)\n",
        "# cnn_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'], run_eagerly=True)\n",
        "# cnn_model.summary()"
      ],
      "metadata": {
        "id": "5y1WoLKLtt3p",
        "outputId": "3151aeba-7f8f-4e7c-c8e6-eed56c06f281",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 256, 256, 16)      448       \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 256, 256, 16)     64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 128, 128, 16)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 128, 128, 16)      0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 128, 128, 32)      4640      \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 128, 128, 32)     128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 64, 64, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 64, 64, 32)        0         \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 131072)            0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 512)               67109376  \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 3)                 1539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67,116,195\n",
            "Trainable params: 67,116,099\n",
            "Non-trainable params: 96\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odrWjuB-hKRF",
        "outputId": "f88b3e9f-0779-4e74-ad19-5668bdaf6213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-plot\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.10.1)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.3.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-plot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize = (6,6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    cm = np.round(cm,2)\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1Nky3aNEqELw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YDvUMUphWyY",
        "outputId": "6463283a-b8cd-4fea-e852-684955890b80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28/28 [==============================] - 1s 29ms/step\n",
            "7/7 [==============================] - 0s 26ms/step\n",
            "(877, 1024)\n"
          ]
        }
      ],
      "source": [
        "extractCNN = Model(cnn_model.inputs, cnn_model.layers[-2].output)\n",
        "\n",
        "#del(data)\n",
        "#del(labels)\n",
        "feat_trainCNN  = extractCNN.predict(x_train)\n",
        "feat_testCNN = extractCNN.predict(x_test)\n",
        "\n",
        "print(feat_trainCNN.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwNaYsLKhjPJ",
        "outputId": "d0ef4e35-e282-4ecb-d253-bfc44fac316c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Training Accuracy Score:- 100.0\n",
            "\n",
            "SVM Testing Accuracy Score:- 98.18181818181819\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n",
        "\n",
        "TrainSVMScoreCNN=svm.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\n",
        "print(\"SVM Training Accuracy Score:-\",TrainSVMScoreCNN)\n",
        "\n",
        "TestSVMScoreCNN=svm.score(feat_testCNN,np.argmax(y_test,axis=1))*100\n",
        "print(\"\\nSVM Testing Accuracy Score:-\",TestSVMScoreCNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MIzKIZfhqqC",
        "outputId": "6cb44862-4e36-4118-c0be-010752f49387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Training Accuracy Score:- 100.0\n",
            "\n",
            "Decision Tree Testing Accuracy Score:- 89.54545454545455\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=0)\n",
        "clf = clf.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n",
        "\n",
        "TrainDecisionScoreCNN=clf.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\n",
        "print(\"Decision Tree Training Accuracy Score:-\",TrainDecisionScoreCNN)\n",
        "\n",
        "\n",
        "TestDecisionScoreCNN=clf.score(feat_testCNN,np.argmax(y_test,axis=1))*100\n",
        "print(\"\\nDecision Tree Testing Accuracy Score:-\",TestDecisionScoreCNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBnKNWgChyWV",
        "outputId": "cf216d22-65c0-44fb-dbb6-9323abfd373b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Training Accuracy Score:- 98.51767388825542\n",
            "\n",
            "KNN Testing Accuracy Score:- 97.27272727272728\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n",
        "\n",
        "TrainKNNScoreCNN=knn.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\n",
        "print(\"KNN Training Accuracy Score:-\",TrainKNNScoreCNN)\n",
        "\n",
        "TestKNNScoreCNN=knn.score(feat_testCNN,np.argmax(y_test,axis=1))*100\n",
        "print(\"\\nKNN Testing Accuracy Score:-\",TestKNNScoreCNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gux9LyNoh5f7",
        "outputId": "89748321-fc1e-4325-f378-6bbedc1391db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GaussianNaive Bayes Training Accuracy Score:- 82.09806157354618\n",
            "\n",
            "GaussianNaive Bayes Testing Accuracy Score:- 69.54545454545455\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n",
        "\n",
        "TrainNBScoreCNN=gnb.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\n",
        "print(\"\\nGaussianNaive Bayes Training Accuracy Score:-\",TrainNBScoreCNN)\n",
        "\n",
        "TestNBScoreCNN=gnb.score(feat_testCNN,np.argmax(y_test,axis=1))*100\n",
        "print(\"\\nGaussianNaive Bayes Testing Accuracy Score:-\",TestNBScoreCNN)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}