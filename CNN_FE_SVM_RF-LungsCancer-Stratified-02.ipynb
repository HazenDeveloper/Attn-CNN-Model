{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HazenDeveloper/Attn-CNN-Model/blob/main/CNN_FE_SVM_RF-LungsCancer-Stratified-02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IUzMl-LWi0Pl",
        "outputId": "02767515-6d86-4f32-b02c-10e9aec51811",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bFbjIBEyceKU"
      },
      "outputs": [],
      "source": [
        "#!pip install imutils\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "from keras.layers import Input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import Input\n",
        "from keras.layers import BatchNormalization\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model\n",
        "from sklearn.utils import shuffle\n",
        "from cv2 import imread\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4fuzmF_0Yvr",
        "outputId": "d4249013-db1b-4ad8-e4a0-71e491b9fa99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<built-in method count of list object at 0x7f935f48f800>\n"
          ]
        }
      ],
      "source": [
        "from os import listdir, walk\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from imutils import paths\n",
        "\n",
        "path = list(paths.list_images('/content/drive/MyDrive/ML-Datasets/LungsCancer'))\n",
        "print(([i.split(os.path.sep)[-2] for i in path]))\n",
        "\n",
        "# print('testing', imagePaths[1].split(os.path.sep)[-2])\n",
        "\n",
        "# img = cv2.imread(imagePaths[2])\n",
        "# cv2_imshow(img)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3NJxQMYNe0cC",
        "outputId": "419ecefe-7c8e-4780-899e-68230556dc61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1097 1097\n",
            "(1097, 256, 256, 3)\n",
            "(1097, 3)\n"
          ]
        }
      ],
      "source": [
        "data = []\n",
        "labels = []\n",
        "width,height=256,256\n",
        "depth = 3\n",
        "input_shape = (height, width, depth)\n",
        "\n",
        "classes = 3\n",
        "\n",
        "imagePaths = list(paths.list_images('/content/drive/MyDrive/ML-Datasets/LungsCancer'))\n",
        "\n",
        "train_data_dir = '/content/drive/MyDrive/ML-Datasets/LungsCancer/Normal'\n",
        "test_data_dir = '/content/drive/MyDrive/ML-Datasets/LungsCancer/Bengin'\n",
        "valid_data_dir = '/content/drive/MyDrive/ML-Datasets/LungsCancer/Malignant'\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for imagePath in imagePaths:\n",
        "    label = imagePath.split(os.path.sep)[-2]\n",
        "    image = load_img(imagePath, target_size=(width, height))\n",
        "    image = img_to_array(image)\n",
        "    data.append(image)\n",
        "    labels.append(label)\n",
        "\n",
        "data = np.array(data, dtype=\"float32\")\n",
        "labels = np.array(labels)\n",
        "print(len(data), len(labels))\n",
        "\n",
        "from sklearn.preprocessing import  LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# le = LabelEncoder()\n",
        "# labels = le.fit_transform(labels)\n",
        "\n",
        "# ohe = OneHotEncoder()\n",
        "# labels = ohe.fit_transform(labels)\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "\n",
        "#labels = to_categorical(labels)\n",
        "\n",
        "data, labels = shuffle(data, labels)\n",
        "\n",
        "print(data.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7P7hNcblOobe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtJkMb8RgeP3",
        "outputId": "b64cc0b7-fe25-4722-9c25-d15b197c9609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images: (877, 256, 256, 3)\n",
            "Test images: (220, 256, 256, 3)\n",
            "Train label: (877, 3)\n",
            "Test label: (220, 3)\n"
          ]
        }
      ],
      "source": [
        "test_ratio = 0.2\n",
        "# train is now 75% of the entire data set\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=test_ratio)\n",
        "\n",
        "print(\"Train images:\",x_train.shape)\n",
        "print(\"Test images:\",x_test.shape)\n",
        "print(\"Train label:\",y_train.shape)\n",
        "print(\"Test label:\",y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xx_train, x_valid, yy_train, y_valid = train_test_split(x_train, y_train,test_size=test_ratio)"
      ],
      "metadata": {
        "id": "miBqYK_eylzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train images:\",x_train.shape)\n",
        "print(\"Test images:\",x_valid.shape)\n",
        "print(\"Train label:\",y_train.shape)\n",
        "print(\"Test label:\",y_valid.shape)"
      ],
      "metadata": {
        "id": "SbJEYBdvy8P5",
        "outputId": "09b5eb54-a5b2-4e8b-b2e2-de4fef9ccb68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images: (768, 256, 256, 3)\n",
            "Test images: (192, 256, 256, 3)\n",
            "Train label: (768, 4)\n",
            "Test label: (192, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train.shape[0])"
      ],
      "metadata": {
        "id": "87BtFGvszq8F",
        "outputId": "396c456a-9caa-4310-8fff-b948bddc9cf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MiniVGGNet(width, heigth, depth, classes):\n",
        "\tmodel = Sequential()\n",
        "\tinput_shape = (heigth, width, depth)\n",
        "\tchanDim = -1\n",
        "\n",
        "\tif keras.backend.image_data_format() == \"channel_first\":\n",
        "\t\tinput_shape = (depth, heigth, width)\n",
        "\t\tchanDim = 1\n",
        "\n",
        "\tmodel.add(Conv2D(16,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\t# model.add(Conv2D(32,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\t# model.add(Conv2D(64,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(Conv2D(32,(3,3), padding=\"same\", activation=\"relu\"))\n",
        "\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\t# model.add(Conv2D(64,(3,3), padding=\"same\", activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\t# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\t# model.add(Dropout(0.25))\n",
        "\n",
        "\t# model.add(Conv2D(128,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\t# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\t# model.add(Dropout(0.25))\n",
        "\n",
        "\t# model.add(BatchNormalization())\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(512, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization())\n",
        "\t# model.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(classes, activation=\"softmax\"))\n",
        "\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "0YVgmPybsCro"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install scikit-plot\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# import scikitplot as skplt\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "import tensorflow\n",
        "\n",
        "# cnn_model = tensorflow.keras.models.load_model('best_model.h5')\n",
        "# x_test = test_generator\n",
        "# x_train = train_generator\n",
        "# y_test = test_generator.classes\n",
        "def plot_results(h):\n",
        "  # plot the training loss and accuracy\n",
        "  N = EPOCHS\n",
        "  plt.style.use(\"ggplot\")\n",
        "  plt.figure()\n",
        "  plt.plot(np.arange(0, N), h.history[\"loss\"], label=\"train_loss\")\n",
        "  plt.plot(np.arange(0, N), h.history[\"val_loss\"], label=\"val_loss\")\n",
        "  plt.title(\"Training Loss vs. validation Loss\")\n",
        "  plt.xlabel(\"Epoch #\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend(loc=\"lower left\",)\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(np.arange(0, N), h.history[\"accuracy\"], label=\"train_acc\")\n",
        "  plt.plot(np.arange(0, N), h.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "  plt.title(\"Training Accuracy vs. Validation Accuracy\")\n",
        "  plt.xlabel(\"Epoch #\")\n",
        "  plt.ylabel(\"Loss/Accuracy\")\n",
        "  plt.legend(loc=\"lower left\",)\n",
        "  plt.show()\n",
        "\n",
        "def evaluate_kth_fold(x_train, x_test, y_train, y_test):\n",
        "  print(\"[INFO] evaluating network...\")\n",
        "  predIdxs = cnn_model.predict(x_test)#, batch_size=BS)\n",
        "  predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "  trainpredIdxs = cnn_model.predict(x_train)#, batch_size=BS)\n",
        "  trainpredIdxs = np.argmax(trainpredIdxs, axis=1)\n",
        "\n",
        "  trainCNNScore=accuracy_score(trainpredIdxs,y_train.argmax(axis=1))*100\n",
        "  CNNScore=accuracy_score(predIdxs,y_test.argmax(axis=1))*100\n",
        "\n",
        "  return trainCNNScore, CNNScore"
      ],
      "metadata": {
        "id": "8t8sidYQj_GD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MiniVGGNetv01(model):\n",
        "  chanDim = -1\n",
        "  width,height=256,256\n",
        "  depth = 3\n",
        "  input_shape = (height, width, depth)\n",
        "\n",
        "  if keras.backend.image_data_format() == \"channel_first\":\n",
        "    input_shape = (depth, heigth, width)\n",
        "    chanDim = 1\n",
        "\n",
        "\n",
        "  model.add(Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  # model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  # model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "  # model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "  # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  # model.add(Dropout(0.25))\n",
        "\n",
        "  # model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "  # model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "  # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  # model.add(Dropout(0.25))\n",
        "\n",
        "  # model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "  # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  # model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, activation=\"relu\"))\n",
        "  # model.add(BatchNormalization())\n",
        "  # model.add(Dropout(0.25))\n",
        "  model.add(Dense(classes, activation=\"softmax\"))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "OhMc3MUUrC6d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path where you want to save the best model\n",
        "checkpoint_path = 'best_model.h5'\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Create the ModelCheckpoint callback\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    patience = 2,\n",
        "    monitor='val_accuracy',       # Metric to monitor (could also be 'val_accuracy', etc.)\n",
        "    save_best_only=True,      # Saves only the best model based on the monitored metric\n",
        "    # save_weights_only=False,  # Set to True to save only the model's weights, not the whole model\n",
        "    verbose=1                 # Verbosity level: 0 - silent, 1 - progress bar, 2 - one line per epoch.\n",
        ")\n",
        "# checkpoint_callback = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "early_stopping_callback = EarlyStopping(monitor='val_accuracy', patience=6, mode='auto')\n",
        "my_callbacks = [model_checkpoint, early_stopping_callback]"
      ],
      "metadata": {
        "id": "xAGgR5THejdM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width,height=256,256\n",
        "depth = 3\n",
        "input_shape = (height, width, depth)\n",
        "\n",
        "classes = 3\n",
        "depth = 3\n",
        "INIT_LR = 1e-3\n",
        "EPOCHS = 100\n",
        "BS=32\n",
        "\n",
        "from keras.optimizers import Nadam, SGD\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "h = []\n",
        "Kfold = StratifiedKFold(n_splits=8)\n",
        "for train, test in Kfold.split(x_train, y_train.argmax(axis=1)):\n",
        "  cnn_model = Sequential()\n",
        "  # opt = Nadam(learning_rate=INIT_LR)\n",
        "  opt = SGD(learning_rate=INIT_LR)\n",
        "  # opt = Adam(learning_rate=INIT_LR)\n",
        "\n",
        "  cnn_model = MiniVGGNet(width, height, depth, classes)\n",
        "  cnn_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])#, run_eagerly=True)\n",
        "  # cnn_model.summary()\n",
        "  h = cnn_model.fit(x_train[train], y_train[train], epochs=EPOCHS, batch_size=BS, validation_split = 0.2, callbacks=my_callbacks)\n",
        "  print(\"Done !!\")\n",
        "\n",
        "  trainCNNScore, CNNScore = evaluate_kth_fold(x_train[train], x_test, y_train[test], y_test)\n",
        "\n",
        "  print(\"\\nTrainig Accuracy Score:-\",trainCNNScore)\n",
        "  print(\"\\nTesting Accuracy Score:-\",CNNScore)\n",
        "  print(\"\\nTraning Graph:- \\n \")\n",
        "\n",
        "  plot_results(h)\n",
        "\n",
        "  # cnn_model = MiniVGGNetv01(model)\n",
        "# opt = gradient_descent_legacy.SGD (learning_rate = INIT_LR)\n",
        "# cnn_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'], run_eagerly=True)\n",
        "# cnn_model.summary()"
      ],
      "metadata": {
        "id": "5y1WoLKLtt3p",
        "outputId": "8723c5f6-dd71-45c6-bbb4-a871e3b843ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4872 - accuracy: 0.7253\n",
            "Epoch 1: val_accuracy did not improve from 0.99351\n",
            "20/20 [==============================] - 3s 104ms/step - loss: 1.4755 - accuracy: 0.7276 - val_loss: 3.0024 - val_accuracy: 0.4221\n",
            "Epoch 2/100\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.1269 - accuracy: 0.9622\n",
            "Epoch 2: val_accuracy did not improve from 0.99351\n",
            "20/20 [==============================] - 2s 80ms/step - loss: 0.1261 - accuracy: 0.9625 - val_loss: 1.1052 - val_accuracy: 0.5455\n",
            "Epoch 3/100\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.0569 - accuracy: 0.9852\n",
            "Epoch 3: val_accuracy did not improve from 0.99351\n",
            "20/20 [==============================] - 2s 79ms/step - loss: 0.0565 - accuracy: 0.9853 - val_loss: 0.3092 - val_accuracy: 0.8571\n",
            "Epoch 4/100\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.0345 - accuracy: 0.9951\n",
            "Epoch 4: val_accuracy did not improve from 0.99351\n",
            "20/20 [==============================] - 2s 79ms/step - loss: 0.0343 - accuracy: 0.9951 - val_loss: 0.1120 - val_accuracy: 0.9740\n",
            "Epoch 5/100\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.0269 - accuracy: 0.9934\n",
            "Epoch 5: val_accuracy did not improve from 0.99351\n",
            "20/20 [==============================] - 2s 80ms/step - loss: 0.0268 - accuracy: 0.9935 - val_loss: 0.0929 - val_accuracy: 0.9805\n",
            "Epoch 6/100\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.0184 - accuracy: 0.9984\n",
            "Epoch 6: val_accuracy did not improve from 0.99351\n",
            "20/20 [==============================] - 2s 90ms/step - loss: 0.0187 - accuracy: 0.9984 - val_loss: 0.0642 - val_accuracy: 0.9935\n",
            "Epoch 7/100\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.0149 - accuracy: 0.9984\n",
            "Epoch 7: val_accuracy did not improve from 0.99351\n",
            "20/20 [==============================] - 2s 84ms/step - loss: 0.0148 - accuracy: 0.9984 - val_loss: 0.0580 - val_accuracy: 0.9935\n",
            "Epoch 8/100\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.0124 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 0.99351\n",
            "20/20 [==============================] - 2s 88ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9935\n",
            "Epoch 9/100\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.0108 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 0.99351\n",
            "20/20 [==============================] - 2s 85ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9870\n",
            "Epoch 10/100\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.0103 - accuracy: 0.9984\n",
            "Epoch 10: val_accuracy did not improve from 0.99351\n",
            "20/20 [==============================] - 2s 83ms/step - loss: 0.0103 - accuracy: 0.9984 - val_loss: 0.0498 - val_accuracy: 0.9870\n",
            "Epoch 11/100\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.0088 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 0.99351\n",
            "20/20 [==============================] - 2s 85ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9935\n",
            "Epoch 12/100\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.99351\n",
            "20/20 [==============================] - 2s 82ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9870\n",
            "Done !!\n",
            "[INFO] evaluating network...\n",
            "7/7 [==============================] - 0s 16ms/step\n",
            "24/24 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-a637dfa1a3b1>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done !!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   \u001b[0mtrainCNNScore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCNNScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_kth_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTrainig Accuracy Score:-\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainCNNScore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-b4a75691a130>\u001b[0m in \u001b[0;36mevaluate_kth_fold\u001b[0;34m(x_train, x_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0mtrainpredIdxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainpredIdxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m   \u001b[0mtrainCNNScore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainpredIdxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m   \u001b[0mCNNScore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredIdxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [767, 110]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odrWjuB-hKRF",
        "outputId": "f88b3e9f-0779-4e74-ad19-5668bdaf6213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-plot\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.10.1)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.3.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-plot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize = (6,6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    cm = np.round(cm,2)\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1Nky3aNEqELw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YDvUMUphWyY",
        "outputId": "6463283a-b8cd-4fea-e852-684955890b80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28/28 [==============================] - 1s 29ms/step\n",
            "7/7 [==============================] - 0s 26ms/step\n",
            "(877, 1024)\n"
          ]
        }
      ],
      "source": [
        "extractCNN = Model(cnn_model.inputs, cnn_model.layers[-2].output)\n",
        "\n",
        "#del(data)\n",
        "#del(labels)\n",
        "feat_trainCNN  = extractCNN.predict(x_train)\n",
        "feat_testCNN = extractCNN.predict(x_test)\n",
        "\n",
        "print(feat_trainCNN.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwNaYsLKhjPJ",
        "outputId": "d0ef4e35-e282-4ecb-d253-bfc44fac316c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Training Accuracy Score:- 100.0\n",
            "\n",
            "SVM Testing Accuracy Score:- 98.18181818181819\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n",
        "\n",
        "TrainSVMScoreCNN=svm.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\n",
        "print(\"SVM Training Accuracy Score:-\",TrainSVMScoreCNN)\n",
        "\n",
        "TestSVMScoreCNN=svm.score(feat_testCNN,np.argmax(y_test,axis=1))*100\n",
        "print(\"\\nSVM Testing Accuracy Score:-\",TestSVMScoreCNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MIzKIZfhqqC",
        "outputId": "6cb44862-4e36-4118-c0be-010752f49387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Training Accuracy Score:- 100.0\n",
            "\n",
            "Decision Tree Testing Accuracy Score:- 89.54545454545455\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=0)\n",
        "clf = clf.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n",
        "\n",
        "TrainDecisionScoreCNN=clf.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\n",
        "print(\"Decision Tree Training Accuracy Score:-\",TrainDecisionScoreCNN)\n",
        "\n",
        "\n",
        "TestDecisionScoreCNN=clf.score(feat_testCNN,np.argmax(y_test,axis=1))*100\n",
        "print(\"\\nDecision Tree Testing Accuracy Score:-\",TestDecisionScoreCNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBnKNWgChyWV",
        "outputId": "cf216d22-65c0-44fb-dbb6-9323abfd373b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Training Accuracy Score:- 98.51767388825542\n",
            "\n",
            "KNN Testing Accuracy Score:- 97.27272727272728\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n",
        "\n",
        "TrainKNNScoreCNN=knn.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\n",
        "print(\"KNN Training Accuracy Score:-\",TrainKNNScoreCNN)\n",
        "\n",
        "TestKNNScoreCNN=knn.score(feat_testCNN,np.argmax(y_test,axis=1))*100\n",
        "print(\"\\nKNN Testing Accuracy Score:-\",TestKNNScoreCNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gux9LyNoh5f7",
        "outputId": "89748321-fc1e-4325-f378-6bbedc1391db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GaussianNaive Bayes Training Accuracy Score:- 82.09806157354618\n",
            "\n",
            "GaussianNaive Bayes Testing Accuracy Score:- 69.54545454545455\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n",
        "\n",
        "TrainNBScoreCNN=gnb.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\n",
        "print(\"\\nGaussianNaive Bayes Training Accuracy Score:-\",TrainNBScoreCNN)\n",
        "\n",
        "TestNBScoreCNN=gnb.score(feat_testCNN,np.argmax(y_test,axis=1))*100\n",
        "print(\"\\nGaussianNaive Bayes Testing Accuracy Score:-\",TestNBScoreCNN)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}