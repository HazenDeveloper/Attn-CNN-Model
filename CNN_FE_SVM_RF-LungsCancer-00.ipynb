{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HazenDeveloper/Attn-CNN-Model/blob/main/CNN_FE_SVM_RF-LungsCancer-00.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IUzMl-LWi0Pl",
        "outputId": "c3361b16-a95c-4ea3-9c6a-e65305f5e508",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bFbjIBEyceKU"
      },
      "outputs": [],
      "source": [
        "#!pip install imutils\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "from keras.layers import Input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import Input\n",
        "from keras.layers import BatchNormalization\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model\n",
        "from sklearn.utils import shuffle\n",
        "from cv2 import imread\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4fuzmF_0Yvr",
        "outputId": "36411b5b-90de-450d-8e49-31b2d025fea2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML-Datasets/Messidore\n"
          ]
        }
      ],
      "source": [
        "from os import listdir, walk\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "path = os.path.join(os.path.curdir,'/content/drive/MyDrive/ML-Datasets/LungsCancer')\n",
        "print(path)\n",
        "\n",
        "# print('testing', imagePaths[1].split(os.path.sep)[-2])\n",
        "\n",
        "# img = cv2.imread(imagePaths[2])\n",
        "# cv2_imshow(img)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3NJxQMYNe0cC",
        "outputId": "e68781ca-45c0-4aeb-a22b-c4a69cd4931c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1097 1097\n",
            "(1097, 256, 256, 3)\n",
            "(1097, 3)\n"
          ]
        }
      ],
      "source": [
        "data = []\n",
        "labels = []\n",
        "width,height=256,256\n",
        "depth = 3\n",
        "input_shape = (height, width, depth)\n",
        "\n",
        "classes = 4\n",
        "\n",
        "imagePaths = list(paths.list_images('/content/drive/MyDrive/ML-Datasets/LungsCancer'))\n",
        "\n",
        "train_data_dir = '/content/drive/MyDrive/ML-Datasets/LungsCancer/Normal'\n",
        "test_data_dir = '/content/drive/MyDrive/ML-Datasets/LungsCancer/Bengin'\n",
        "valid_data_dir = '/content/drive/MyDrive/ML-Datasets/LungsCancer/Malignant'\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for imagePath in imagePaths:\n",
        "    label = imagePath.split(os.path.sep)[-2]\n",
        "    image = load_img(imagePath, target_size=(width, height))\n",
        "    image = img_to_array(image)\n",
        "    data.append(image)\n",
        "    labels.append(label)\n",
        "\n",
        "data = np.array(data, dtype=\"float32\")\n",
        "labels = np.array(labels)\n",
        "print(len(data), len(labels))\n",
        "\n",
        "from sklearn.preprocessing import  LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# le = LabelEncoder()\n",
        "# labels = le.fit_transform(labels)\n",
        "\n",
        "# ohe = OneHotEncoder()\n",
        "# labels = ohe.fit_transform(labels)\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "\n",
        "#labels = to_categorical(labels)\n",
        "\n",
        "data, labels = shuffle(data, labels)\n",
        "\n",
        "print(data.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtJkMb8RgeP3",
        "outputId": "cc925215-9fd3-48de-edee-160adaf56404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images: (877, 256, 256, 3)\n",
            "Test images: (220, 256, 256, 3)\n",
            "Train label: (877, 3)\n",
            "Test label: (220, 3)\n"
          ]
        }
      ],
      "source": [
        "test_ratio = 0.2\n",
        "# train is now 75% of the entire data set\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=test_ratio)\n",
        "\n",
        "print(\"Train images:\",x_train.shape)\n",
        "print(\"Test images:\",x_test.shape)\n",
        "print(\"Train label:\",y_train.shape)\n",
        "print(\"Test label:\",y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train,test_size=test_ratio)"
      ],
      "metadata": {
        "id": "miBqYK_eylzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train images:\",x_train.shape)\n",
        "print(\"Test images:\",x_valid.shape)\n",
        "print(\"Train label:\",y_train.shape)\n",
        "print(\"Test label:\",y_valid.shape)"
      ],
      "metadata": {
        "id": "SbJEYBdvy8P5",
        "outputId": "09b5eb54-a5b2-4e8b-b2e2-de4fef9ccb68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images: (768, 256, 256, 3)\n",
            "Test images: (192, 256, 256, 3)\n",
            "Train label: (768, 4)\n",
            "Test label: (192, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train.shape[0])"
      ],
      "metadata": {
        "id": "87BtFGvszq8F",
        "outputId": "396c456a-9caa-4310-8fff-b948bddc9cf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = ImageDataGenerator(rescale = 1./255.0,\n",
        "                             rotation_range=15,\n",
        "                             zoom_range=0.2,\n",
        "                             shear_range=0.1)\n",
        "\n",
        "test_x = ImageDataGenerator(rescale = 1./255.0\n",
        "                             )\n",
        "valid_x = ImageDataGenerator(rescale = 1./255.0)\n",
        "\n",
        "trainData = train_x.flow(x_train, y_train)#,\n",
        "#                         #  batch_size=batch_size),\n",
        "#                         #  samples_per_epoch=X_train.shape[0],\n",
        "#                         #  nb_epoch=nb_epoch,\n",
        "#                         #  validation_data=(x_valid, y_valid),\n",
        "#                          class_mode='categorical')\n",
        "\n",
        "testData = test_x.flow(x_test, y_test)#,\n",
        "                    #  input_shape[:2],\n",
        "                    #  batch_size=x_test[0],\n",
        "                    #  class_mode='categorical')\n",
        "\n",
        "validData = test_x.flow(x_valid, y_valid)#,\n",
        "                    #  target_size=input_shape[:2],\n",
        "                    #  batch_size=x_test[0],\n",
        "                    #  class_mode='categorical')"
      ],
      "metadata": {
        "id": "s8_qhn6hpR-b",
        "outputId": "f3f3f134-b388-4003-c37a-5bb24d1fe03b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-87646433d517>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mvalid_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrainData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#                         #  batch_size=batch_size),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#                         #  samples_per_epoch=X_train.shape[0],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLE4RO53NyW0"
      },
      "outputs": [],
      "source": [
        "!pip install lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=False, custom_metric=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 32\n",
        "\n",
        "# Preprocess the training data with data augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,            # Normalize pixel values to [0, 1]\n",
        "                                  #  rotation_range=15,         # Randomly rotate images by 10 degrees\n",
        "                                  #  width_shift_range=0.1,   # Randomly shift images horizontally by 10% of the width\n",
        "                                   # height_shift_range=0.1,  # Randomly shift images vertically by 10% of the height\n",
        "                                   # shear_range=0.1,         # Apply shear transformation with a shear angle of 10 degrees\n",
        "                                  #  zoom_range=0.2,          # Apply random zoom between 0.9x and 1.1x\n",
        "                                  #  horizontal_flip=True,    # Randomly flip images horizontally\n",
        "                                  #  vertical_flip=False      # Do not flip images vertically\n",
        "                                   )\n",
        "\n",
        "# Preprocess the validation and testing data (only rescale pixel values)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "# Load and augment the training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=BS,\n",
        "    class_mode='categorical'   # Use categorical mode for multi-class classification\n",
        ")\n",
        "\n",
        "# Load the validation data\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    valid_data_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=BS,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load the testing data\n",
        "test_generator = valid_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=BS,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "id": "VzEdrvd5ynTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "415fcb7a-0ff5-4e19-e450-9086effff593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 838 images belonging to 4 classes.\n",
            "Found 238 images belonging to 4 classes.\n",
            "Found 124 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MiniVGGNet(width, heigth, depth, classes):\n",
        "\tmodel = Sequential()\n",
        "\tinput_shape = (heigth, width, depth)\n",
        "\tchanDim = -1\n",
        "\n",
        "\tif keras.backend.image_data_format() == \"channel_first\":\n",
        "\t\tinput_shape = (depth, heigth, width)\n",
        "\t\tchanDim = 1\n",
        "\n",
        "\tmodel.add(Conv2D(16,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\t# model.add(Conv2D(32,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\t# model.add(Conv2D(64,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(Conv2D(32,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\tmodel.add(Conv2D(64,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\tmodel.add(Conv2D(128,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\t# model.add(BatchNormalization())\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(512, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization())\n",
        "\t# model.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(classes, activation=\"softmax\"))\n",
        "\n",
        "\treturn model\n"
      ],
      "metadata": {
        "id": "0YVgmPybsCro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MiniVGGNetv01(model):\n",
        "  chanDim = -1\n",
        "  width,height=256,256\n",
        "  depth = 3\n",
        "  input_shape = (height, width, depth)\n",
        "\n",
        "  if keras.backend.image_data_format() == \"channel_first\":\n",
        "    input_shape = (depth, heigth, width)\n",
        "    chanDim = 1\n",
        "\n",
        "\n",
        "  model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
        "  # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  # model.add(Dropout(0.25))\n",
        "\n",
        "  # model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  # model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "  # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  # model.add(Dropout(0.25))\n",
        "\n",
        "  # model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, activation=\"relu\"))\n",
        "  # model.add(BatchNormalization())\n",
        "  # model.add(Dropout(0.25))\n",
        "  model.add(Dense(classes, activation=\"softmax\"))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "OhMc3MUUrC6d"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width,height=256,256\n",
        "depth = 3\n",
        "input_shape = (height, width, depth)\n",
        "\n",
        "classes = 3\n",
        "depth = 3\n",
        "INIT_LR = 1e-3\n",
        "EPOCHS = 100\n",
        "BS=32\n",
        "\n",
        "from keras.optimizers import Nadam, SGD\n",
        "model = Sequential()\n",
        "\n",
        "# cnn_model = MiniVGGNet(width, height, depth, classes)\n",
        "cnn_model = MiniVGGNetv01(model)\n",
        "\n",
        "# opt = Nadam(learning_rate=INIT_LR)\n",
        "opt = SGD(learning_rate=INIT_LR)\n",
        "# opt = Adam(learning_rate=INIT_LR)\n",
        "# opt = gradient_descent_legacy.SGD (learning_rate = INIT_LR)\n",
        "cnn_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'], run_eagerly=True)\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "id": "5y1WoLKLtt3p",
        "outputId": "0a7946b6-9fdc-4245-d372-70b1bb564745",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_26 (Conv2D)          (None, 256, 256, 32)      896       \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 256, 256, 32)      9248      \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 128, 128, 32)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 128, 128, 32)      0         \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 128, 128, 64)      18496     \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 128, 128, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 64, 64, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 64, 64, 32)        18464     \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 32, 32, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1024)              33555456  \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 3)                 3075      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33,642,563\n",
            "Trainable params: 33,642,563\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path where you want to save the best model\n",
        "checkpoint_path = 'best_model.h5'\n",
        "\n",
        "# Create the ModelCheckpoint callback\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    patience = 2,\n",
        "    monitor='val_accuracy',       # Metric to monitor (could also be 'val_accuracy', etc.)\n",
        "    save_best_only=True,      # Saves only the best model based on the monitored metric\n",
        "    # save_weights_only=False,  # Set to True to save only the model's weights, not the whole model\n",
        "    verbose=1                 # Verbosity level: 0 - silent, 1 - progress bar, 2 - one line per epoch.\n",
        ")\n",
        "# checkpoint_callback = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "# early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, mode='auto')\n",
        "my_callbacks = [model_checkpoint]"
      ],
      "metadata": {
        "id": "oDaSr1KbyVcx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uk-YNu0kgpnZ",
        "outputId": "b5b3e867-ce9d-4b5b-815d-3e9e6a2133f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training head..\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 15.0839 - accuracy: 0.4337\n",
            "Epoch 1: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 17s 501ms/step - loss: 15.0839 - accuracy: 0.4337 - val_loss: 1.0561 - val_accuracy: 0.3920\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9404 - accuracy: 0.5064\n",
            "Epoch 2: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.9404 - accuracy: 0.5064 - val_loss: 0.9963 - val_accuracy: 0.5455\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9054 - accuracy: 0.5307\n",
            "Epoch 3: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.9054 - accuracy: 0.5307 - val_loss: 1.0110 - val_accuracy: 0.6193\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8615 - accuracy: 0.5792\n",
            "Epoch 4: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.8615 - accuracy: 0.5792 - val_loss: 0.8955 - val_accuracy: 0.6307\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7934 - accuracy: 0.6562\n",
            "Epoch 5: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.7934 - accuracy: 0.6562 - val_loss: 0.8269 - val_accuracy: 0.6761\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7418 - accuracy: 0.6833\n",
            "Epoch 6: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.7418 - accuracy: 0.6833 - val_loss: 0.7275 - val_accuracy: 0.7102\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6933 - accuracy: 0.7090\n",
            "Epoch 7: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.6933 - accuracy: 0.7090 - val_loss: 0.6974 - val_accuracy: 0.7273\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6930 - accuracy: 0.7061\n",
            "Epoch 8: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.6930 - accuracy: 0.7061 - val_loss: 0.6891 - val_accuracy: 0.7102\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6716 - accuracy: 0.7275\n",
            "Epoch 9: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.6716 - accuracy: 0.7275 - val_loss: 0.7510 - val_accuracy: 0.6193\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.5985 - accuracy: 0.7575\n",
            "Epoch 10: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.5985 - accuracy: 0.7575 - val_loss: 0.6025 - val_accuracy: 0.7614\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.5704 - accuracy: 0.7732\n",
            "Epoch 11: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.5704 - accuracy: 0.7732 - val_loss: 0.5986 - val_accuracy: 0.7784\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.5726 - accuracy: 0.7760\n",
            "Epoch 12: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.5726 - accuracy: 0.7760 - val_loss: 0.5649 - val_accuracy: 0.8125\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.5303 - accuracy: 0.7960\n",
            "Epoch 13: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.5303 - accuracy: 0.7960 - val_loss: 0.5290 - val_accuracy: 0.7727\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.4875 - accuracy: 0.8003\n",
            "Epoch 14: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.4875 - accuracy: 0.8003 - val_loss: 0.4406 - val_accuracy: 0.8523\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.4460 - accuracy: 0.8274\n",
            "Epoch 15: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 261ms/step - loss: 0.4460 - accuracy: 0.8274 - val_loss: 0.4193 - val_accuracy: 0.8636\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.4826 - accuracy: 0.8174\n",
            "Epoch 16: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.4826 - accuracy: 0.8174 - val_loss: 0.5193 - val_accuracy: 0.7898\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.4244 - accuracy: 0.8402\n",
            "Epoch 17: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 263ms/step - loss: 0.4244 - accuracy: 0.8402 - val_loss: 0.4864 - val_accuracy: 0.7955\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.3617 - accuracy: 0.8545\n",
            "Epoch 18: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.3617 - accuracy: 0.8545 - val_loss: 0.4563 - val_accuracy: 0.8068\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.4041 - accuracy: 0.8459\n",
            "Epoch 19: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 262ms/step - loss: 0.4041 - accuracy: 0.8459 - val_loss: 0.4723 - val_accuracy: 0.8523\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.3672 - accuracy: 0.8602\n",
            "Epoch 20: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.3672 - accuracy: 0.8602 - val_loss: 0.4111 - val_accuracy: 0.8352\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.4162 - accuracy: 0.8445\n",
            "Epoch 21: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.4162 - accuracy: 0.8445 - val_loss: 0.3904 - val_accuracy: 0.9091\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.3100 - accuracy: 0.8702\n",
            "Epoch 22: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.3100 - accuracy: 0.8702 - val_loss: 0.3958 - val_accuracy: 0.8807\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.2851 - accuracy: 0.9001\n",
            "Epoch 23: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.2851 - accuracy: 0.9001 - val_loss: 0.2837 - val_accuracy: 0.9148\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.2877 - accuracy: 0.8859\n",
            "Epoch 24: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 263ms/step - loss: 0.2877 - accuracy: 0.8859 - val_loss: 0.2903 - val_accuracy: 0.9261\n",
            "Epoch 25/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.2783 - accuracy: 0.8916\n",
            "Epoch 25: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 0.2783 - accuracy: 0.8916 - val_loss: 0.2796 - val_accuracy: 0.9205\n",
            "Epoch 26/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.2463 - accuracy: 0.9144\n",
            "Epoch 26: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.2463 - accuracy: 0.9144 - val_loss: 0.2669 - val_accuracy: 0.9432\n",
            "Epoch 27/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.2005 - accuracy: 0.9301\n",
            "Epoch 27: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.2005 - accuracy: 0.9301 - val_loss: 0.3453 - val_accuracy: 0.8636\n",
            "Epoch 28/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.2828 - accuracy: 0.8987\n",
            "Epoch 28: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.2828 - accuracy: 0.8987 - val_loss: 0.2657 - val_accuracy: 0.9375\n",
            "Epoch 29/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.2083 - accuracy: 0.9215\n",
            "Epoch 29: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.2083 - accuracy: 0.9215 - val_loss: 0.2530 - val_accuracy: 0.9375\n",
            "Epoch 30/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1945 - accuracy: 0.9173\n",
            "Epoch 30: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1945 - accuracy: 0.9173 - val_loss: 0.3459 - val_accuracy: 0.9205\n",
            "Epoch 31/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1654 - accuracy: 0.9444\n",
            "Epoch 31: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.1654 - accuracy: 0.9444 - val_loss: 0.2090 - val_accuracy: 0.9432\n",
            "Epoch 32/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1704 - accuracy: 0.9387\n",
            "Epoch 32: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.1704 - accuracy: 0.9387 - val_loss: 0.2155 - val_accuracy: 0.9318\n",
            "Epoch 33/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1572 - accuracy: 0.9444\n",
            "Epoch 33: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 261ms/step - loss: 0.1572 - accuracy: 0.9444 - val_loss: 0.2329 - val_accuracy: 0.9261\n",
            "Epoch 34/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1621 - accuracy: 0.9301\n",
            "Epoch 34: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1621 - accuracy: 0.9301 - val_loss: 0.2921 - val_accuracy: 0.9375\n",
            "Epoch 35/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1805 - accuracy: 0.9358\n",
            "Epoch 35: val_accuracy did not improve from 0.94886\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.1805 - accuracy: 0.9358 - val_loss: 0.1962 - val_accuracy: 0.9489\n",
            "Epoch 36/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1470 - accuracy: 0.9572\n",
            "Epoch 36: val_accuracy improved from 0.94886 to 0.95455, saving model to best_model.h5\n",
            "22/22 [==============================] - 45s 2s/step - loss: 0.1470 - accuracy: 0.9572 - val_loss: 0.2022 - val_accuracy: 0.9545\n",
            "Epoch 37/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1212 - accuracy: 0.9615\n",
            "Epoch 37: val_accuracy improved from 0.95455 to 0.96023, saving model to best_model.h5\n"
          ]
        }
      ],
      "source": [
        "from keras.engine.training import callbacks_module\n",
        "# train the head of the network\n",
        "print(\"[INFO] training head..\")\n",
        "# print(train_generator.shape, test_generator.shape)\n",
        "BS=32\n",
        "# x_train = train_generator\n",
        "# y_train = train_generator.classes\n",
        "# print (len(y_train))\n",
        "\n",
        "h = cnn_model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BS, validation_split=0.2, callbacks=my_callbacks)\n",
        "\n",
        "# h = cnn_model.fit(\n",
        "#         train_generator,\n",
        "#         # steps_per_epoch=len(train_generator) // BS,\n",
        "#         epochs=EPOCHS,\n",
        "#         validation_data=valid_generator,\n",
        "#         # validation_steps=len(valid_generator) // BS)\n",
        "#         callbacks = my_callbacks\n",
        "#         )\n",
        "print(\"Done !!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odrWjuB-hKRF",
        "outputId": "f88b3e9f-0779-4e74-ad19-5668bdaf6213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-plot\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.10.1)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.3.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-plot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize = (6,6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    cm = np.round(cm,2)\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1Nky3aNEqELw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "XoFY_Xm6g-KO",
        "outputId": "4a2aa713-37bd-45e6-e0b6-0c48f53f586d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f4aff5230d63>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# x_test = test_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# x_train = train_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    565\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 567\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (bad object header version number)"
          ]
        }
      ],
      "source": [
        "#!pip install scikit-plot\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scikitplot as skplt\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "import tensorflow\n",
        "\n",
        "cnn_model = tensorflow.keras.models.load_model('best_model.h5')\n",
        "# x_test = test_generator\n",
        "# x_train = train_generator\n",
        "# y_test = test_generator.classes\n",
        "\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predIdxs = cnn_model.predict(x_test)#, batch_size=BS)\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "trainpredIdxs = cnn_model.predict(x_train)#, batch_size=BS)\n",
        "trainpredIdxs = np.argmax(trainpredIdxs, axis=1)\n",
        "\n",
        "trainCNNScore=accuracy_score(trainpredIdxs,y_train.argmax(axis=1))*100\n",
        "CNNScore=accuracy_score(predIdxs,y_test.argmax(axis=1))*100\n",
        "\n",
        "print(\"\\nTrainig Accuracy Score:-\",trainCNNScore)\n",
        "print(\"\\nTesting Accuracy Score:-\",CNNScore)\n",
        "print(\"\\nTraning Graph:- \\n \")\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "N = EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), h.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), h.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Training Loss vs. validation Loss\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc=\"lower left\",)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), h.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), h.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Accuracy vs. Validation Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\",)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YDvUMUphWyY",
        "outputId": "6463283a-b8cd-4fea-e852-684955890b80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28/28 [==============================] - 1s 29ms/step\n",
            "7/7 [==============================] - 0s 26ms/step\n",
            "(877, 1024)\n"
          ]
        }
      ],
      "source": [
        "extractCNN = Model(cnn_model.inputs, cnn_model.layers[-2].output)\n",
        "\n",
        "#del(data)\n",
        "#del(labels)\n",
        "feat_trainCNN  = extractCNN.predict(x_train)\n",
        "feat_testCNN = extractCNN.predict(x_test)\n",
        "\n",
        "print(feat_trainCNN.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwNaYsLKhjPJ",
        "outputId": "d0ef4e35-e282-4ecb-d253-bfc44fac316c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Training Accuracy Score:- 100.0\n",
            "\n",
            "SVM Testing Accuracy Score:- 98.18181818181819\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n",
        "\n",
        "TrainSVMScoreCNN=svm.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\n",
        "print(\"SVM Training Accuracy Score:-\",TrainSVMScoreCNN)\n",
        "\n",
        "TestSVMScoreCNN=svm.score(feat_testCNN,np.argmax(y_test,axis=1))*100\n",
        "print(\"\\nSVM Testing Accuracy Score:-\",TestSVMScoreCNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MIzKIZfhqqC",
        "outputId": "6cb44862-4e36-4118-c0be-010752f49387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Training Accuracy Score:- 100.0\n",
            "\n",
            "Decision Tree Testing Accuracy Score:- 89.54545454545455\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=0)\n",
        "clf = clf.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n",
        "\n",
        "TrainDecisionScoreCNN=clf.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\n",
        "print(\"Decision Tree Training Accuracy Score:-\",TrainDecisionScoreCNN)\n",
        "\n",
        "\n",
        "TestDecisionScoreCNN=clf.score(feat_testCNN,np.argmax(y_test,axis=1))*100\n",
        "print(\"\\nDecision Tree Testing Accuracy Score:-\",TestDecisionScoreCNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBnKNWgChyWV",
        "outputId": "cf216d22-65c0-44fb-dbb6-9323abfd373b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Training Accuracy Score:- 98.51767388825542\n",
            "\n",
            "KNN Testing Accuracy Score:- 97.27272727272728\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n",
        "\n",
        "TrainKNNScoreCNN=knn.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\n",
        "print(\"KNN Training Accuracy Score:-\",TrainKNNScoreCNN)\n",
        "\n",
        "TestKNNScoreCNN=knn.score(feat_testCNN,np.argmax(y_test,axis=1))*100\n",
        "print(\"\\nKNN Testing Accuracy Score:-\",TestKNNScoreCNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gux9LyNoh5f7",
        "outputId": "89748321-fc1e-4325-f378-6bbedc1391db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GaussianNaive Bayes Training Accuracy Score:- 82.09806157354618\n",
            "\n",
            "GaussianNaive Bayes Testing Accuracy Score:- 69.54545454545455\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n",
        "\n",
        "TrainNBScoreCNN=gnb.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\n",
        "print(\"\\nGaussianNaive Bayes Training Accuracy Score:-\",TrainNBScoreCNN)\n",
        "\n",
        "TestNBScoreCNN=gnb.score(feat_testCNN,np.argmax(y_test,axis=1))*100\n",
        "print(\"\\nGaussianNaive Bayes Testing Accuracy Score:-\",TestNBScoreCNN)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}